\chapter{Background}\label{chapter:background}

This chapter gives an overview of prerequisites upon which we build our
cross-chain protocols.

\section{Notation}
We use standard mathematical notation throughout this work. We define all the
non-standard or unusual notation in this section. We use standard cryptographic
notation, which is also introduced here for reference. The reader unfamiliar
with this notation can consult some reference book in the subject such
as~\cite{katz} for a more complete treatment.

Given a distribution $\mathcal{M}$, we denote by $m \gets \mathcal{M}$ the experiment by which the random variable $m$ is chosen according to the distribution $\mathcal{M}$. Given a finite set $M$, we use $\uniform(M)$ to denote the uniform distribution which assigns probability $1 / 2^{|M|}$ to each element $m \in M$. We will use $m \getsrandomly M$ to denote the experiment in which $m$ is sampled from $\uniform(M)$.

As a shorthand for probabilities and to avoid excessive subscripting, we will write the experimental set up (such as the sampling of random variables) within the $\Pr[\cdot]$ prior to the predicate of interest and separated by $;\,$. For example, $\Pr[x \gets \mathcal{D}_1, y \gets \mathcal{D}_2; x + y = 1]$ denotes the experiment of independently sampling two random variables, $x$ and $y$, from the distributions $\mathcal{D}_1$ and $\mathcal{D}_2$ respectively, summing their values, and observing whether their sum is equal to $1$.

\subsection{Asymptotic probabilistic security}
Following the extended Church--Turing definition, we consider the class of
problems in $\textsc{P}$ to be \emph{easy}, and we call \emph{hard} those which
are not easy~\cite{sipser}. It is assumed that all honest parties and the adversary have polynomial available time. Both the honest parties and the adversary have access to true randomness and are thus probabilistic Turing Machines.
The shorthand \emph{PPT} is used to denote a probabilistic polynomial-time
Turing machine.

Our theorems are by computational reduction, in which we show that bad
events happen only with negligible probability in some security parameter, which
we will denote $\lambda \in \mathbb{N}$. This parameter allows all our
cryptographic primitives to be instantiated with the required level of security;
for example, it provides the number of bits in the output of our hash function.

\begin{definition}[Negligible]
  A function $f: \mathbb{N} \longrightarrow \mathbb{R}^+$ is
  \emph{negligible} if for all $k \in \mathbb{N}$ it holds that
  $f \in \mathcal{O}(\frac{1}{\lambda^k})$.
\end{definition}

We will use the notation $\negl$ to denote any negligible function.

\begin{definition}[Overwhelming]
  A function $f: \mathbb{N} \longrightarrow \mathbb{R}^+$ is
  \emph{overwhelming} if it can be written as $f(n) = 1 - \negl(n)$ for
  some negligible function $\negl$.
\end{definition}

We will define the \emph{security} of various cryptographic protocols by making use of challenger-adversary games in which the challenger is a known Turing Machine defined by us, but the adversary is an \emph{arbitrary} Turing Machine. Herein lies the beauty of cryptography as a science; it allows us to create protocols which we prove secure against \emph{any} adversary, even those we cannot conceive. A protocol will be considered \emph{secure} if no PPT adversary can win the respective game, except with negligible probability.

\subsection{Sequences}
We use $[n]$ to denote the set of natural numbers from $0$ up to and including
$n$. We also use $[\mathcal{M}]$ to denote the support of a distribution
$\mathcal{M}$; the distinction between the two notations will be clear from
context.
We use $\epsilon$ to denote the empty sequence (or empty string). We write
one sequence next to another to denote string concatenation. Likewise, we
concatenate sequences to symbols by juxtaposition.

Our sequences are indexed starting at $0$. Given a sequence $\chain$, we use
$|\chain|$ to denote its length. We use Python notation to denote sequence
addressing. For $i \in [n - 1]$, we denote the $i^\text{th}$ element from the
beginning as $\chain[i]$. The first element of the sequence is thus $\chain[0]$.
For $i \in [n] \setminus \{0\}$, we denote the $i^\text{th}$ element from the
end as $\chain[-i]$. The last element of the sequence is thus $\chain[-1]$. We
call this the \emph{tip} of the sequence. Given $i \in \mathbb{Z},
j \in \mathbb{Z}$ with $i \leq j$, we denote $\chain[i{:}j]$ the subsequence from
$i$ (inclusive) to $j$ (exclusive), that is the sequence which contains exactly
the elements $\chain[i], \chain[i + 1], \dots, \chain[j - 1]$. If $i > j$, then
by convention we set $\chain[i{:}j] = \epsilon$. We allow this \emph{range}
notation to be used with negative indices as well, indicating ranges starting or
ending (or both) in indices considered from the end of the sequence, hence
allowing for $\chain[-i{:}j], \chain[i{:}-j]$, and $\chain[-i{:}-j]$. The left end of
a range can omitted if it is $i = 0$. The right end of a range can be omitted if
it is $j = |\chain|$. For example, $\chain[:-k]$ is the sequence $\chain$ with
the last $k$ elements excluded. In this example, if $|\chain| < k$, then
$\chain[:-k] = \epsilon$.

If an element $A$ is a member of a sequence $\chain$ we will use the notation $A
\in \chain$ to denote this, i.e. that there exist words $w, v$ such that $\chain
= wAv$. It will be clear from the context whether we are speaking about sequence
or sets. Given $A, Z \in \chain$ such that $A$ and $Z$ exist only once in
$\chain$, we denote by $\chain\{A{:}Z\}$ the subsequence of $\chain$ starting from
$A$ (inclusive) and ending in $Z$ (exclusive). If $A = \chain[0]$, it can be
omitted. Omitting $Z$ denotes the sequence starting with $A$ and containing all
subsequent elements until the end of the sequence.

% TODO: \chain\{A:Z\} notation (inclusive, exclusive). But how to include Z?
\section{Cryptographic Primitives}

We now overview the cryptographic primitives we will make use of. In particular,
cryptographically secure hash functions, public-key signatures, and
proof-of-work. Notably, similar to most blockchain protocols, we will not be
using any encryption or decryption. This section is a review. For a full
treatment, refer to any introductory textbook in the subject~\cite{katz,handbook,foundations1,foundations2}.

\subsection{Hash Functions}
A hash function $H^s: \mathcal{M} \longrightarrow \{0, 1\}^\lambda$ is a function
parameterized by the security parameter $\lambda$ which takes any string from the distribution of input strings $\mathcal{M}$ and
outputs a string of constant size $\lambda$. To capture the fact that the hash
function behaves like a randomly chosen function, the hash
function is instantiated using a key-generating function
$\textsf{Gen}(1^\lambda)$ which generates a hash key $s$. The hash function itself is then $H^s$, a different function for each value of the key $s$. As hash functions are the building blocks and workhoses of cryptography, other protocols are designed on top of them that make use of them. We will do so in this work. In practice, the key $s$ is assumed to have been generated by the designers of the higher level protocol that makes use of the hash function and is typically fixed and publicly known. The hash protocol is the tuple $\Pi = (\textsf{Gen}, H)$.

Practical hash functions allow us to map any message $x$ of arbitrary length
$x \in \{0, 1\}^*$ to a fixed-length bitstring $\{0, 1\}^\lambda$. Hash
functions are easy to compute, but hard to invert. In applications, it is
assumed that a hash uniquely represents its preimage (it is \emph{binding}) and
that the preimage cannot be discovered from the image given sufficient entropy
(it is \emph{hiding}).

These intuitive ideas are captured by the difficulty of finding
collisions in hash functions. This is formalized in the next definition.

\input{./chapters/background/algorithms/alg.collision-resistance.tex}

\begin{definition}[Collision resistance]
  A hash function $H: \{0, 1\}^* \longrightarrow \{0, 1\}^\lambda$ is called
  \emph{collision resistant} if for all PPT adversaries $\mathcal{A}$ there is a
  negligible function $\negl$ such that

  \[
  \Pr[\textsf{hash-collision}_{\Pi,\mathcal{A}} = 1] \leq \negl(\lambda)\,.
  \]
\end{definition}

A weaker notion of security mandates that no adversary can reverse the function (pre-image resistance) or that no adversary can find a second value giving the same output as a given random value. The two cryptographic games and definitions are illustrated in Algorithms~\ref{alg.hash-preimage} and~\ref{alg.hash-second-preimage}.

\input{./chapters/background/algorithms/alg.hash-preimage.tex}
\input{./chapters/background/algorithms/alg.hash-second-preimage.tex}

\begin{definition}[Pre-image resistance]
  A hash function $H: \{0, 1\}^* \longrightarrow \{0, 1\}^\lambda$ is called
  \emph{pre-image resistant} if for all PPT adversaries $\mathcal{A}$ there is a
  negligible function $\negl$ such that

  \[
  \Pr[\textsf{hash-preimage}_{\Pi,\mathcal{A}} = 1] \leq \negl(\lambda)\,.
  \]
\end{definition}

\begin{definition}[Second pre-image resistance]
  A hash function $H: \{0, 1\}^* \longrightarrow \{0, 1\}^\lambda$ is called
  \emph{second pre-image resistant} if for all PPT adversaries $\mathcal{A}$
  there is a negligible function $\negl$ such that

  \[
  \Pr[\textsf{hash-second-preimage}_{\Pi,\mathcal{A}} = 1] \leq \negl(\lambda)\,.
  \]
\end{definition}

A hash function that is collision-resistant is also pre-image resistant; additionally, if it is pre-image resistant, then it must also be second pre-image resistant, as long as it provides sufficient compression~\cite{rogaway2004cryptographic}.

Protocols deployed in practice make use of fixed hash functions; that is, hash
functions with a fixed security parameter and a fixed key. In Bitcoin, the hash
function $\SHA$~\cite{sha256} is used for both commitments and proof-of-work.
Its domain and range are
$\SHA: \{0, 1\}^* \longrightarrow \{0, 1\}^{256}$. In Ethereum, the hash
function $\keccak$~\cite{bertoni2008indifferentiability}, a variant of
$\texttt{SHA3}$, is used for commitments. Its domain and range are $\keccak: \{0, 1\}^*
\longrightarrow \{0, 1\}^{256}$. The function used for proof-of-work is a
variant of this.

\subsection{Signatures}
A \emph{digital signature} allows parties to authenticate the origin of a
message as well as its integrity~\cite{katz}. If Alice signs a message $m$, she generates a
signature $\sigma$ which is uniquely associated with that message. That
signature can then only be used to verify that particular message. In a secure signature scheme, an adversary
cannot \emph{forge} signatures that correctly verify for messages that have not
been signed by the honest party.

Signing and verification are two separate tasks which are asymmetric. Only the
authorized party can sign a message, but anyone can verify the signature. This
is achieved by having each party generate their own \emph{public-private
key pair} $(pk, sk)$ in which $pk$ is the public key and $sk$ is the secret key.
Signatures are then generated using the secret (or signing) key $sk$ and
verified using the public (or verification) key $sk$. A key pair is generated
using the polynomial-time key generation algorithm $(pk, sk) \gets
\Gen(1^\lambda)$. A signature is generated by invoking the polynomial-time
signing algorithm $\sigma = \Sig(sk, m)$. Verification is done by checking
whether the verification algorithm $\Ver(pk, m, \sigma)$ returns $\true$ or
$\false$. The signature scheme $\Pi$ then is defined as the tuple
$\Pi = (\Gen, \Sig, \Ver)$.

Signature schemes must be \emph{correct}.

\begin{definition}[Signature correctness]
  A signature scheme is \emph{correct} if there is a
  negligible function $\negl$ such that for all messages $m \in \{0, 1\}^*$ it
  holds that

  \[
    \Pr[(pk, sk) \gets \Gen(1^\lambda); \Ver(pk, m, \Sig(sk, m)) = \false] < \negl(\lambda)\,.
  \]
\end{definition}

A \emph{secure} signature scheme requires that no adversary is able to forge
signatures. This is captured in the game-based definition of Algorithm~\ref{alg.forgery}. In this game, the challenger first generates a public/private key pair by invoking $\Gen(1^\lambda)$. Subsequently, the challenger asks the adversary $\mathcal{A}$ to attempt to find a signature forgery. The adversary is allowed to ask the challenger to have any messages signed by invoking the ${\Sig}O$ oracle with messages of her choice. The adversary is allowed to make multiple adaptive queries to the oracle. When the adversary is ready, she presents a message $m$, which she must not have requested from the oracle ${\Sig}O$ and a signature $\sigma$. The adversary is successful if the signature verifies.

\input{./chapters/background/algorithms/alg.forgery.tex}

\begin{definition}[Security]
  A signature scheme $\Pi = (\Gen, \Sig, \Ver)$ is \emph{secure} if for all PPT adversaries $\mathcal{A}$ there is a negligible function $\negl$ such that

  \[
  \Pr[\textsc{sig-forge}_{\Pi,\mathcal{A}}(\lambda)] < \negl(\lambda)\,.
  \]
\end{definition}

There are multiple ways to construct a secure signature scheme. Our signature schemes of interest make use of the \emph{discrete logarithm} problem in a group. In such a construction, a cyclic group $\mathbb{G}$ with order close to $2^\lambda$ and a generator $G \in \mathbb{G}$ are fixed initially. A public key corresponds to an element $A \in G$ of the group, while the corresponding private key $a \in \mathbb{Z}_{|\mathbb{G}|}$ is the order of $A$ with respect to $G$, that is $A = aG$. The keys are generated by first choosing a private key $a$ uniformly at random and then computing its corresponding public key. The public key can be computed quickly from the private key using multiplication by doubling~\cite{shoup}, but it is believed that the inverse problem is hard.

The problem of finding $a$ from $A$ is made formal in Algorithm~\ref{alg.dlog}. Here, we assume that an efficient algorithm $\mathcal{G}$ can be used to pick a suitable group of the appropriate order and output its description. Furthermore, we assume the group operator is efficiently computable. The challenger generates a group and chooses one of its elements at random. The adversary is then asked to find the \emph{discrete logarithm} of that element.

\input{./chapters/background/algorithms/alg.dlog.tex}

\begin{definition}[Discrete Logarithm Problem]
  The \emph{discrete logarithm problem} is hard in the family of groups $\{\mathcal{G}(1^\lambda)\}_{\lambda \in \mathbb{N}}$ if for all PPT adversaries $\mathcal{A}$ there is a negligible function $\negl$ such that

  \[
    \Pr[\textsf{DLOG}_{\mathcal{G},\mathcal{A}}(\lambda) = 1] < \negl(\lambda)\,.
  \]
\end{definition}

The particular instantiation of signature schemes in the context of
cryptocurrencies makes use of elliptic curves~\cite{ec} in which the discrete logarithm problem is believed to be hard. More specifically, Bitcoin
and Ethereum both use the \texttt{secp256k1} curve~\cite{secp256k1}.

\begin{remark}
We remark that, perhaps contrary to popular belief, blockchain protocols
do not depend at all on encryption primitives. Therefore, we choose not to
treat encryption at all in the present work.
\end{remark}

\subsection{Proof-of-Work}

\todo{Copy lecture notes from our \emph{Introduction to Blockchains} course for the next sections...}

\section{The Transaction Layer}
\subsection{Transactions}
\subsection{The UTXO Model}
\subsection{The Account Model}

\section{Authenticated Data Structures}
\subsection{Merkle Trees}
\subsection{Merkleâ€“Patricia Tries}

\section{Blockchains}
\subsection{The Consensus Problem}
\subsection{Blocks}
\subsection{Chains of Blocks}
\subsection{Blockchain Addressing}
\subsection{SPV}

\section{Cryptocurrencies}

\subsection{Bitcoin}
\subsection{Ethereum}

\section{Smart Contracts}
\subsection{Bitcoin Script}
\subsection{Solidity}

\input{chapters/background/math}
\section{Model}
\subsection{The Random Oracle}

Real protocols are instantiated using real hash functions. However, as concrete
mathematical objects, these are not possible to analyze cryptographically, as
they do not have a security parameter. For example, \texttt{SHA256} is a
function with a fixed size of $256$ bits. In these terms, one cannot talk about
negligible probability of failure. Keyed hash functions in which the function
depends on the security parameter are possible to analyze in this manner, but
their use is limited in practice. Additionally, many of the guarantees provided
by keyed hash functions discussed above are insufficient for more elaborate
protocols. In particular, collision and preimage resistance are not enough for
our needs. Nevertheless, our intuition is that practical concrete hash functions
behave nicely, and we wish to include this notion in our model.

To bypass these limitations, we model our hash functions in the Random Oracle
model~\cite{ro}. In this model, the hash function behaves like an ideal random
function. This is helpful, because we can argue all of its outputs will be
unbiased and independent. This abstraction also signifies that we are interested
in working in the realm of \emph{protocol design}, and the intricacies of
practical hash function design and implementation, which stands in the realm of
efficient symmetric cryptography, are beyond the scope of our work.

In the Random Oracle model, we assume the existence of a global oracle machine
$H$ to which every party, adversarial or honest, has access to. The machine
models the hash function and hence allows parties to ask for its evaluation at
any input. The Random Oracle machine receives any input in $\{0, 1\}^*$ and
returns an output in $\{0, 1\}^\lambda$.

\input{./chapters/background/algorithms/alg.ro.tex}

The output is chosen as illustrated in Algorithm~\ref{alg.ro}. In detail, the
Random Oracle is parameterized by the security parameter $\lambda$. Upon
receiving some input $x$, if the input has not been encountered before, then it
produces a fresh uniformly random $\lambda$-bit string which it stores in a
dictionary $T$ and returns. If on the other hand it receives an input it has
seen before, it answers consistently with its previous answer, giving the same
answer for the same query by consulting the dictionary $T$. Hence, this
functionality is stateful.

It is imperative that the instance of the machine that all parties communicate
with is the same. Hence, if a party makes a particular query $x$ to the oracle
and then another party asks the same query, the answer will be the same. If the
random oracle is modelled as a stateful functionality, communication between the
parties and the Random Oracle machine can be modelled as Interactive Turing
Machines communicating.

Alterantively but equivalently, the Random Oracle can be defined as a shared
oracle which answers queries according to a function selected uniformly at
random at the beginning of the execution. As a random function can neither be
sampled in polynomial time nor represented in polynomial space, this latter
formulation means that, when the oracle is treated that way, it cannot be
modelled as an Interactive Turing Machine, but must remain an oracle. In this
formulation, at the beginning of the execution, the random oracle $H$ is sampled
uniformly at random from the function space $(\{0, 1\}^\lambda)^{\{0, 1\}^*}$,
and the adversary and honest parties are invoked with oracle access to this same
$H$. As all parties will be polynomial in our treatment, this sampling can also
be understood to be done uniformly at random from the function space $(\{0,
1\}^\lambda)^{\{0, 1\}^{p(\kappa)}}$ where $p(\kappa)$ denotes the polynomial
bounding the total execution of all parties together.

An important feature of the Random Oracle model is that the adversary cannot
compute $H$ locally, but must invokve the oracle to do so. This means that, in
our mathematical treatment, we are allowed to speak of the queries the adversary
has made, count them, look at their responses, and so on. This ability, termed
\emph{random oracle observability} will be critical in our analyses. On the
other hand, we will not make use of the ability of a computational reduction to
modify the outputs of the random oracle at will, termed \emph{random oracle
programmability}, which is at the heart of many security proofs in cryptography.
Our results are therefore stronger, as we only assume a \emph{non-programmable}
Random Oracle~\cite{nielsen2002separating,fischlin2010random}, which is a weaker
assumption than usually made.

% Random Oracles as machines and as random functions
\input{chapters/background/synchrony}

\subsection{Blockchain Backbone}
\todo{Restore old NIPoPoWs paper backbone overview section}

% Honest Majority Assumption
% Chain Growth
% Common Prefix
% Chain Quality
% The Constant Difficulty assumption and its relaxation
\subsection{The Common Reference String}
\todo{Move Proof-of-Burn paper appendix notes here}

% Mention that CRS is not needed (due to Bootstrapping the Blockchain - Directly paper)
% Epochs
\input{chapters/background/ouroboros}
